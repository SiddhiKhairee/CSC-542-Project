{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\siddh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining necesarry paths\n",
    "data_dir = \"CUB_200_2011\\\\CUB_200_2011\\\\images\"\n",
    "train_test_split_file = \"CUB_200_2011\\\\CUB_200_2011\\\\train_test_split.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, root_dir, split_file, transform=None, train=True):\n",
    "        self.root_dir = os.path.join(root_dir, \"images\")  # Point to images folder\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Read images.txt to map image_ids to filenames\n",
    "        image_id_to_filename = {}\n",
    "        with open(os.path.join(root_dir, \"images.txt\"), 'r') as f:\n",
    "            for line in f:\n",
    "                img_id, filename = line.strip().split()\n",
    "                image_id_to_filename[int(img_id)] = filename\n",
    "        \n",
    "        # Read train_test_split.txt\n",
    "        with open(split_file, 'r') as f:\n",
    "            for line in f:\n",
    "                img_id, is_train = line.strip().split()\n",
    "                if int(is_train) == (1 if train else 0):\n",
    "                    filename = image_id_to_filename[int(img_id)]\n",
    "                    self.image_paths.append(os.path.join(self.root_dir, filename))\n",
    "                    # Get class_id from image_class_labels.txt\n",
    "                    class_id = int(filename.split('.')[0].split('_')[0]) - 1  # Convert to 0-199\n",
    "                    self.labels.append(class_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing the images for faster training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Larger input size\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\C'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\C'\n",
      "C:\\Users\\siddh\\AppData\\Local\\Temp\\ipykernel_22872\\4247175256.py:6: SyntaxWarning: invalid escape sequence '\\C'\n",
      "  root_dir = 'CUB_200_2011\\CUB_200_2011'  # Main folder containing images.txt, etc.\n"
     ]
    }
   ],
   "source": [
    "# making train and test dataset as per the txt file 1 -> training // 0 -> testing\n",
    "# Create datasets\n",
    "# train_dataset = BirdDataset(data_dir, train_test_split_file, transform=transform, train=True)\n",
    "# test_dataset = BirdDataset(data_dir, train_test_split_file, transform=transform, train=False)\n",
    "# Define paths (adjust to your actual structure)\n",
    "root_dir = 'CUB_200_2011\\CUB_200_2011'  # Main folder containing images.txt, etc.\n",
    "split_file = os.path.join(root_dir, \"train_test_split.txt\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BirdDataset(root_dir, split_file, transform=transform, train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = BirdDataset(root_dir, split_file, transform=transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Model is a simple VGG inspired model\n",
    "A VGG Model is is a convolutional neural network (CNN) architecture known for its simplicity and effectiveness in image recognition tasks.\n",
    "\n",
    "VGG Architecture in our case:\n",
    "We have 5 convolutional layers\n",
    "1 pooling layer\n",
    "2 fully connected layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(nn.Module):\n",
    "     def __init__(self, num_classes=200):\n",
    "        super(BaselineModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 2\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 14 * 14, 512),  # 224x224 → 14x14 after 4 maxpool layers\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "     def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.3363\n",
      "Epoch 2, Loss: 5.2998\n",
      "Epoch 3, Loss: 5.2996\n",
      "Epoch 4, Loss: 5.3008\n",
      "Epoch 5, Loss: 5.3001\n",
      "Epoch 6, Loss: 5.2981\n",
      "Epoch 7, Loss: 5.2983\n",
      "Epoch 8, Loss: 5.2986\n",
      "Epoch 9, Loss: 5.2982\n",
      "Epoch 10, Loss: 5.2988\n",
      "Epoch 11, Loss: 5.2976\n",
      "Epoch 12, Loss: 5.2979\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel(num_classes=200).to(device)\n",
    "# Use AdamW optimizer (better than vanilla Adam)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # LR decay\n",
    "\n",
    "# Train for 20 epochs\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 4.89%\n",
      "Test Accuracy: 3.56%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "train_accuracy = evaluate(model, train_loader, device)\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy = evaluate(model, test_loader, device)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
